{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "import pandas as pd\n",
    "import pydot\n",
    "import random\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "import multiprocessing\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions to build tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def causal_train_test_split(data, predictors, response, treatment, test_size = 0.25, estimation_size = 0.33):\n",
    "    \n",
    "    global PROP\n",
    "    PROP = 1 - estimation_size\n",
    "    \n",
    "    train_set, test_set = train_test_split(data, test_size=test_size)\n",
    "    training_sample, estimation_sample = train_test_split(train_set, test_size=estimation_size)\n",
    "    training_sample.insert(loc = 0, column = 'TRAIN_ESTIMATION_IND', value = np.ones(len(training_sample)))\n",
    "    estimation_sample.insert(loc = 0, column = 'TRAIN_ESTIMATION_IND', value = np.zeros(len(estimation_sample)))\n",
    "    new_train_set = pd.concat([training_sample, estimation_sample])\n",
    "    new_train_set = new_train_set[['TRAIN_ESTIMATION_IND'] + predictors + treatment + response]\n",
    "    test_set = test_set[predictors + treatment + response]\n",
    "    return new_train_set, test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def data_split(index, value, dataset):\n",
    "    \"\"\" \n",
    "    A function seperate a dataset into two numpy matrices \n",
    "    given the index of an attribute and a split value for that attribute\n",
    "    \n",
    "    Input:\n",
    "    ------\n",
    "        index(int): the index of the columns of the dataset\n",
    "        value(float): the value to be compared with\n",
    "        dataset(numpy array): the dataset to split\n",
    "    \n",
    "    Output:\n",
    "    ------:\n",
    "        left(numpy array): the dataset that is split(left half)\n",
    "        right(numpy array): the dataset that is split(right half)\n",
    "    \n",
    "    \"\"\"\n",
    "    dim = dataset.shape[1]\n",
    "    left, right = np.empty(shape=[0, dim]), np.empty(shape=[0, dim])\n",
    "    for row in dataset:\n",
    "        if row[index] < value:\n",
    "            left = np.append(left, [row], axis = 0)\n",
    "        else:\n",
    "            right = np.append(right, [row], axis = 0)\n",
    "    return left, right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_emse(train, est, row, index):\n",
    "    \n",
    "    # check the cardinality of the training and estimation samples, if size < *threshold*\n",
    "    # then can not do the calculation\n",
    "    train_size = len(train)\n",
    "    est_size = len(est)\n",
    "    \n",
    "    # split both training sample and estimation sample using the same rule\n",
    "    left_train, right_train = data_split(index, row[index], train)\n",
    "    left_est, right_est = data_split(index, row[index], est)\n",
    "    \n",
    "\n",
    "    ### Calculate the estimated treatment effect\n",
    "            \n",
    "    # get the cardinality of training sample for both leaves\n",
    "    left_train_size = len(left_train)\n",
    "    right_train_size = len(right_train)\n",
    "    \n",
    "    # calculate the treatment effect for both leaves, \n",
    "    left_est_response_trt = get_response(left_est, 'treatment') \n",
    "    left_est_response_ctl = get_response(left_est, 'control') \n",
    "    right_est_response_trt = get_response(right_est, 'treatment') \n",
    "    right_est_response_ctl = get_response(right_est, 'control') \n",
    "    #check cardinality of each leaf, make sure each leaf has at least *threshold* (chould be changed by user)\n",
    "    # treatment and n control to do the calculation\n",
    "    \n",
    "    left_trt_effect = left_est_response_trt.mean() - left_est_response_ctl.mean()\n",
    "    right_trt_effect = right_est_response_trt.mean() - right_est_response_ctl.mean()\n",
    "    \n",
    "    # then calculated the estimated squared treatment effect\n",
    "    e_trt_effect = (left_train_size * (left_trt_effect ** 2) + right_train_size * (right_trt_effect ** 2))/(train_size)\n",
    "    \n",
    "            \n",
    "    ### Calculate the estimated variance\n",
    "    left_var = np.var(left_est_response_trt) / PROP + np.var(left_est_response_ctl) / (1 - PROP)\n",
    "    right_var = np.var(right_est_response_trt) / PROP + np.var(right_est_response_ctl) / (1 - PROP)\n",
    "    e_var = (1 / train_size + 1 / est_size) * (left_var + right_var)\n",
    "    \n",
    "    \n",
    "    ### Calculate EMSE\n",
    "    emse = e_trt_effect - e_var    \n",
    "    \n",
    "    return emse\n",
    "    \n",
    "def get_split_emse(dataset, n_predictors):\n",
    " \n",
    "    train = dataset[dataset[:,0] == 1]\n",
    "    est = dataset[dataset[:,0] == 0]\n",
    "    \n",
    "    #get the random n predictors for each node\n",
    "    num_total_predictors = train.shape[1] - 3\n",
    "    predictor_subset_ind = random.sample(range(1, 1 + num_total_predictors), n_predictors)\n",
    "    \n",
    "\n",
    "    # initialize values to return\n",
    "    b_index, b_value, b_score, b_groups = float('inf'), float('inf'), float('-inf'), None\n",
    "    \n",
    "    for index in predictor_subset_ind:\n",
    "        for row in train:\n",
    "            groups = data_split(index, row[index], dataset)\n",
    "            emse = get_emse(train, est, row, index)\n",
    "            # if mse score gets improved (reduced actually), update the information\n",
    "            if emse > b_score:# and emse is not np.nan:\n",
    "                b_index, b_value, b_score, b_groups = index, row[index], emse, groups   \n",
    "                \n",
    "    ret_dict =  {'index':b_index, 'value':b_value, 'groups':b_groups}\n",
    "    return ret_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_response(dataset, trt):\n",
    "    if trt == 'treatment':\n",
    "        return dataset[dataset[:,-2] == 1][:,-1]\n",
    "    elif trt == 'control':\n",
    "        return dataset[dataset[:,-2] == 0][:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get the split based on criterion\n",
    "def get_split(dataset, criterion, n_predictors):\n",
    "    \"\"\" \n",
    "    A function to split the data based on splitting criterion specified by user\n",
    "    \n",
    "    Input:\n",
    "    ------\n",
    "        dataset(np array): a dataset in the form of a numpy matrix\n",
    "        criterion(str): a str to indicate the criterion specified by user\n",
    "    \n",
    "    Output:\n",
    "    ------:\n",
    "        the same output as functions get_split_xxx\n",
    "    \n",
    "    \"\"\"    \n",
    "    if criterion == 'mse':\n",
    "        return get_split_mse(dataset)\n",
    "    if criterion == 'causal':\n",
    "        return get_split_emse(dataset, n_predictors)    \n",
    "    elif criterion == 'gini':\n",
    "        return get_split_gini(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a terminal node value\n",
    "def to_terminal_gini(group):\n",
    "    response = group[:,-1]\n",
    "    return stats.mode(response)[0][0] # this could be optimized\n",
    "\n",
    "def to_terminal_mse(group):\n",
    "    response = group[:,-1]\n",
    "    return np.mean(response)\n",
    "\n",
    "def to_terminal_emse(group):\n",
    "    est_trt = get_response(group, 'treatment')\n",
    "    est_ctl = get_response(group, 'control')\n",
    "    \n",
    "    causal_effect = np.mean(est_trt) - np.mean(est_ctl)\n",
    "    proportion_of_data = (len(est_trt) + len(est_ctl)) / TOTAL_DATA_COUNT\n",
    "    \n",
    "    return causal_effect, round(proportion_of_data * 100, 1)\n",
    "    \n",
    "    \n",
    "def to_terminal(group, criterion):\n",
    "    if criterion == 'gini':\n",
    "        return to_terminal_gini(group)\n",
    "    elif criterion == 'mse':\n",
    "        return to_terminal_mse(group)\n",
    "    elif criterion == 'causal':\n",
    "        return to_terminal_emse(group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create child splits for a node or make terminal\n",
    "def split(node, max_depth, min_size, depth, criterion, n_predictors):\n",
    "    \n",
    "    left, right = node['groups']\n",
    "    \n",
    "    left_train = left[left[:,0] == 1]\n",
    "    left_est = left[left[:,0] == 0]\n",
    "    right_train = right[right[:,0] == 1]\n",
    "    right_est = right[right[:,0] == 0]    \n",
    "    \n",
    "    left_train_response_trt = get_response(left_train, 'treatment')\n",
    "    left_train_response_ctl = get_response(left_train, 'control')\n",
    "    right_train_response_trt = get_response(right_train, 'treatment')\n",
    "    right_train_response_ctl = get_response(right_train, 'control')  \n",
    "    \n",
    "    left_est_response_trt = get_response(left_est, 'treatment')\n",
    "    left_est_response_ctl = get_response(left_est, 'control')\n",
    "    right_est_response_trt = get_response(right_est, 'treatment')\n",
    "    right_est_response_ctl = get_response(right_est, 'control')\n",
    "    \n",
    "    del(node['groups'])\n",
    "    \n",
    "    if len(left) == 0 or len(right) == 0:\n",
    "        node['left'] = node['right'] = to_terminal(np.append(left, right, axis = 0), criterion)\n",
    "        return\n",
    "    \n",
    "    # check for max depth\n",
    "    if depth >= max_depth:\n",
    "        node['left'], node['right'] = to_terminal(left, criterion), to_terminal(right, criterion)\n",
    "        return\n",
    "    \n",
    "    # process left child\n",
    "    if (len(left) <= min_size or len(left_est_response_trt) <= min_size or len(left_est_response_ctl) <= min_size or\n",
    "        len(right_est_response_trt) <= min_size or len(right_est_response_ctl) <= min_size or \n",
    "        len(left_train_response_trt) <= min_size or len(left_train_response_ctl) <= min_size or \n",
    "        len(right_train_response_trt) <= min_size or len(right_train_response_ctl) <= min_size):\n",
    "        node['left'] = to_terminal(left, criterion)\n",
    "    else:\n",
    "        node['left'] = get_split(left, criterion, n_predictors)\n",
    "        if node['left']['groups'] is None:\n",
    "            node['left'] = to_terminal(left, criterion)\n",
    "        else:\n",
    "            split(node['left'], max_depth, min_size, depth+1, criterion, n_predictors)\n",
    "        \n",
    "    # process right child\n",
    "    if (len(right) <= min_size or len(left_est_response_trt) <= min_size or len(left_est_response_ctl) <= min_size or\n",
    "        len(right_est_response_trt) <= min_size or len(right_est_response_ctl) <= min_size or \n",
    "        len(left_train_response_trt) <= min_size or len(left_train_response_ctl) <= min_size or \n",
    "        len(right_train_response_trt) <= min_size or len(right_train_response_ctl) <= min_size):\n",
    "        node['right'] = to_terminal(right, criterion)\n",
    "    else:\n",
    "        node['right'] = get_split(right, criterion, n_predictors)\n",
    "        if node['right']['groups'] is None:\n",
    "            node['right'] = to_terminal(right, criterion)\n",
    "        else:\n",
    "            split(node['right'], max_depth, min_size, depth+1, criterion, n_predictors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Build a decision tree\n",
    "def causalTree(train, max_depth, min_size, criterion, n_predictors):\n",
    "    \n",
    "    global TOTAL_DATA_COUNT, COLUMN_NAMES\n",
    "    TOTAL_DATA_COUNT = len(train)\n",
    "    COLUMN_NAMES = train.columns[1:-2]\n",
    "    \n",
    "    train = np.array(train)\n",
    "    \n",
    "    if criterion == 'mse' or criterion == 'gini':\n",
    "        root = get_split(train, criterion)\n",
    "        #print(root)\n",
    "        split(root, max_depth, min_size, 1, criterion)\n",
    "        \n",
    "    elif criterion == 'causal':\n",
    "        root = get_split(train, criterion, n_predictors)\n",
    "        split(root, max_depth, min_size, 1, criterion, n_predictors)\n",
    "    return root"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions to use causal tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#print out the tree structure\n",
    "def print_tree(node, depth=0):\n",
    "    if isinstance(node, dict):\n",
    "        print('%s[%s < %.3f]' % ((depth * ' ', (COLUMN_NAMES[node['index'] - 1]), node['value'])))\n",
    "        print_tree(node['left'], depth + 1)\n",
    "        print_tree(node['right'], depth + 1)\n",
    "    else:\n",
    "        print('%s[%s, %s%%]' % ((depth * ' ', node[0], node[1])))\n",
    "\n",
    "        \n",
    "#causal effect prediction\n",
    "def causalPredict_helper(node,row):\n",
    "    if row[node['index'] - 1] < node['value']:\n",
    "        if isinstance(node['left'], dict):\n",
    "            return causalPredict_helper(node['left'], row)\n",
    "        else:\n",
    "            return node['left'][0]\n",
    "    else:\n",
    "        if isinstance(node['right'], dict):\n",
    "            return causalPredict_helper(node['right'], row)\n",
    "        else:\n",
    "            return node['right'][0]    \n",
    "            \n",
    "def causalPredict(test, tree):\n",
    "    #get the information of the trainning set and initialize an empty return dataframe\n",
    "    column_names = list(test.columns) + ['pred_causal_effect']\n",
    "    test_matrix = np.array(test)\n",
    "    ret_matrix = np.empty([0, test_matrix.shape[1] + 1])\n",
    "    \n",
    "    #predict for each row\n",
    "    for row in test_matrix:\n",
    "        row = np.insert(row, len(row), causalPredict_helper(tree, row))\n",
    "        ret_matrix = np.append(ret_matrix, [row], axis = 0) \n",
    "    \n",
    "    #return a new dataframe with the predicted value at the end of each row\n",
    "    ret_df = pd.DataFrame(ret_matrix, columns = column_names)\n",
    "\n",
    "    return ret_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rf_sample(train_set, sample_ratio, n_predictors):\n",
    "    ###a helper function to create a new random forest training set\n",
    "    \n",
    "#     #get subset of predictors based on given num of predictors\n",
    "#     num_total_predictors = len(train_set.columns) - 3\n",
    "#     predictor_subset_ind = random.sample(range(1, 1 + num_total_predictors), n_predictors)\n",
    "#     rf_columns = ['TRAIN_ESTIMATION_IND'] + list(train_set.columns[predictor_subset_ind]) + ['trt', 'y']\n",
    "#     train_subset = train_set[rf_columns]\n",
    "    \n",
    "    #get a subset of rows based on given sample ratio with replacement/bootsrap\n",
    "    n_row = int(sample_ratio * len(train_set))\n",
    "    new_train_subset = train_set.sample(n = n_row, replace = True, axis = 0)\n",
    "    \n",
    "    return new_train_subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# function to build a random forest predictor\n",
    "def causalRandomForest(train_set, max_depth, min_size, criterion, sample_ratio, n_predictors, n_trees):\n",
    "    tree_lst = []\n",
    "    for i in range(n_trees):\n",
    "        #get rf sub training data\n",
    "        rf_train_set = rf_sample(train_set, sample_ratio, n_predictors)\n",
    "        #build the tree\n",
    "        tree = causalTree(rf_train_set, max_depth, min_size, criterion, n_predictors)    \n",
    "        tree_lst.append(tree)\n",
    "        \n",
    "    return tree_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predictTestSet(rf, test_set):\n",
    "       \n",
    "    n_trees = len(rf)\n",
    "    n_test_set = len(test_set)\n",
    "    pred_value_list = np.empty([1,n_test_set])\n",
    "    p_value_list = np.empty([1,n_test_set])  \n",
    "    \n",
    "    for tree in rf:\n",
    "        # get the prediction for each tree\n",
    "        pred_df = causalPredict(test_set, tree)\n",
    "        pred_values = np.array(pred_df['pred_causal_effect'])\n",
    "        # aggregate the prediction\n",
    "        pred_value_list = pred_value_list + pred_values\n",
    "        \n",
    "        # get the number of negative causal effect in the prediction\n",
    "        pred_values[pred_values >= 0] = 0 # set positive causal effect to 0\n",
    "        pred_values[pred_values < 0] = 1 # set negative causal effect to 1\n",
    "        p_value_list = p_value_list + pred_values\n",
    "        \n",
    "    #calculate the prediction of bagged trees for each data point\n",
    "    pred_value_rf = np.round_(pred_value_list / n_trees, decimals = 3)\n",
    "    #calculate the p value of bagged trees for each data point\n",
    "    p_value_rf = np.round_(p_value_list / n_trees, decimals = 3)\n",
    "    \n",
    "    #append the prediction and p_value to the dataset\n",
    "    ret_data = test_set.copy()\n",
    "    ret_data['rf_pred_causal_effect'] = pred_value_rf[0]\n",
    "    # calculate the p value against the hypothesis that the causal effect is not 0\n",
    "    ret_data['rf_p_value'] = p_value_rf[0]\n",
    "    ret_data['rf_p_value'] = ret_data['rf_p_value'].apply(lambda row: 2*row if row < 0.5 else 2*(1-row))\n",
    "    \n",
    "    return ret_data        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predictDataPoint(rf, data):\n",
    "    test_set = pd.DataFrame([data], columns = data.keys())\n",
    "    predict_list = []\n",
    "    for tree in rf:\n",
    "        pred_df = causalPredict(test_set, tree)\n",
    "        pred_value = pred_df.iloc[0,-1]\n",
    "        predict_list.append(pred_value)\n",
    "    # calculate the predicted value    \n",
    "    rf_pred_value = round(np.mean(predict_list),3)\n",
    "    # calculate p-value\n",
    "    positive_ratio = sum(x >0 for x in predict_list)/len(predict_list)\n",
    "    if positive_ratio <= 0.5:\n",
    "        p_value = 2*positive_ratio\n",
    "    else:\n",
    "        p_value = 2*(1-positive_ratio)\n",
    "    print(\"Predicted causal effect: \" + str(rf_pred_value) + \"\\n\")\n",
    "    print(\"P-value: \" + str(p_value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test - simulation study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rf_df_rand = pd.read_csv('fake_data_rand_x2.csv')\n",
    "rf_df_25 = pd.read_csv('fake_data_x2_25.csv')\n",
    "rf_df_75 = pd.read_csv('fake_data_x2_75.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### all random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['design1_y']\n"
     ]
    }
   ],
   "source": [
    "# random forest test\n",
    "#get the column names of predictors\n",
    "p_str = ['x1', 'x2','x3', 'x4', 'x5', 'x6', 'x7', 'x8', 'x9', 'x10']\n",
    "#get the column name of response\n",
    "r_str = [['design1_y'],['design2_y'],['design3_y']]\n",
    "#get the column name of treatment\n",
    "t_str = ['treatment']\n",
    "\n",
    "#set a random seed for replication \n",
    "#np.random.seed(42)\n",
    "\n",
    "ret_df_lst_rand = []\n",
    "for res in r_str:\n",
    "    #split the data\n",
    "    np.random.seed(42)\n",
    "    rf_train_set, rf_test_set = causal_train_test_split(rf_df_rand, predictors = p_str, response = res, treatment = t_str)\n",
    "    #get a causal rf predictor\n",
    "    print(res)\n",
    "    rf = causalRandomForest(rf_train_set, max_depth = 3, min_size = 10, \n",
    "                              criterion = 'causal', sample_ratio = 0.8, n_predictors = 6, n_trees = 100)\n",
    "    ret_df = predictTestSet(rf, rf_test_set)\n",
    "    ret_df_lst_rand.append(ret_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = sns.regplot(x = 'x1', y = 'rf_pred_causal_effect', data = ret_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### x2 = 0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# random forest test\n",
    "#get the column names of predictors\n",
    "p_str = ['x1', 'x2','x3', 'x4', 'x5', 'x6', 'x7', 'x8', 'x9', 'x10']\n",
    "#get the column name of response\n",
    "r_str = [['design1_y'],['design2_y'],['design3_y']]\n",
    "#get the column name of treatment\n",
    "t_str = ['treatment']\n",
    "\n",
    "#set a random seed for replication \n",
    "#np.random.seed(42)\n",
    "\n",
    "ret_df_lst_25 = []\n",
    "for res in r_str:\n",
    "    #split the data\n",
    "    np.random.seed(42)\n",
    "    rf_train_set, rf_test_set = causal_train_test_split(rf_df_25, predictors = p_str, response = res, treatment = t_str)\n",
    "    #get a causal rf predictor\n",
    "    print(res)\n",
    "    rf = causalRandomForest(rf_train_set, max_depth = 3, min_size = 10, \n",
    "                              criterion = 'causal', sample_ratio = 0.8, n_predictors = 6, n_trees = 100)\n",
    "    ret_df = predictTestSet(rf, rf_test_set)\n",
    "    ret_df_lst_25.append(ret_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### x2 = 0.75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# random forest test\n",
    "#get the column names of predictors\n",
    "p_str = ['x1', 'x2','x3', 'x4', 'x5', 'x6', 'x7', 'x8', 'x9', 'x10']\n",
    "#get the column name of response\n",
    "r_str = [['design1_y'],['design2_y'],['design3_y']]\n",
    "#get the column name of treatment\n",
    "t_str = ['treatment']\n",
    "\n",
    "#set a random seed for replication \n",
    "#np.random.seed(42)\n",
    "\n",
    "ret_df_lst_75 = []\n",
    "for res in r_str:\n",
    "    #split the data\n",
    "    np.random.seed(42)\n",
    "    rf_train_set, rf_test_set = causal_train_test_split(rf_df_75, predictors = p_str, response = res, treatment = t_str)\n",
    "    #get a causal rf predictor\n",
    "    print(res)\n",
    "    rf = causalRandomForest(rf_train_set, max_depth = 3, min_size = 10, \n",
    "                              criterion = 'causal', sample_ratio = 0.8, n_predictors = 6, n_trees = 100)\n",
    "    ret_df = predictTestSet(rf, rf_test_set)\n",
    "    ret_df_lst_75.append(ret_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:myenv]",
   "language": "python",
   "name": "conda-env-myenv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
