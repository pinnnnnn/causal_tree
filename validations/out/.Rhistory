shiny::runApp('individual_analytics/individual-causal-effects/APP_2')
install_github("susanathey/causalTree")
install.packages("devtools")
library(devtools)
install_github("susanathey/causalTree")
install_github("susanathey/causalTree")
install.packages("devtools")
library(devtools)
install_github("susanathey/causalTree")
install_github("susanathey/causalTree")
#install_github("susanathey/causalTree")
library(causalTree)
install_github("susanathey/causalTree")
R CMD INSTALL
install_github("susanathey/causalTree")
install_github("susanathey/causalTree")
install.packages("readr", type = "source")
install_github("susanathey/causalTree")
install.packages("devtools")
install_github("susanathey/causalTree")
library(devtools)
install_github("susanathey/causalTree")
R CMD INSTALL
devtools::find_rtools(TRUE)
devtools::find_rtools(TRUE)
install.packages("devtools")
install.packages("devtools")
library(devtools)
install_github("susanathey/causalTree")
find_rtools()
assignInNamespace("version_info", c(devtools:::version_info, list("3.5" = list(version_min = "3.3.0", version_max = "99.99.99", path = "bin"))), "devtools"
)
find_rtools()
library(devtools)
assignInNamespace("version_info", c(devtools:::version_info, list("3.5" = list(version_min = "3.3.0", version_max = "99.99.99", path = "bin"))), "devtools")
devtools::install_github("r-lib/devtools")
assignInNamespace("version_info", c(devtools:::version_info, list("3.5" = list(version_min = "3.3.0", version_max = "99.99.99", path = "bin"))), "devtools")
find_rtools()
install_github("susanathey/causalTree")
install_github("susanathey/causalTree")
install_github("susanathey/causalTree")
library(causalTree)
#install_github("susanathey/causalTree")
library(causalTree)
shiny::runApp('individual_analytics/individual-causal-effects/APP_2')
shiny::runApp('individual_analytics/individual-causal-effects/APP_2')
library(htmltools)
library(causalTree)
library(dplyr)
library(ggplot2)
library(plotly)
library(extrafont)
library(ggthemes)
library(shinydashboard)
library(shiny)
library(leaflet)
library(formattable)
library(ggrepel)
library(distances)
library(caret)
install.packages('htmltools')
install.packages("htmltools")
install.packages("causalTree")
install.packages("purrr")
install.packages("dplyr")
install.packages("ggplot2")
install.packages("plotly")
install.packages("extrafont")
install.packages("ggthemes")
install.packages("shinydashboard")
install.packages("shiny")
install.packages("leaflet")
install.packages("formattable")
install.packages("ggrepel")
install.packages("caret")
install.packages("distance")
install.packages("distances")
install.packages("randomForest")
shiny::runApp('individual_analytics/individual-causal-effects/APP_2')
load(file = "//dc3fs1/secure/CFL/Data For AIR Analysts/Leading Indicators/Data/AllObjects_need_for_torun_ShinyApp.RData")
runApp('individual_analytics/individual-causal-effects/APP_2')
load(file = "//dc3fs1/secure/CFL/Data For AIR Analysts/Leading Indicators/Data/AllObjects_need_for_torun_ShinyApp.RData")
runApp('individual_analytics/individual-causal-effects/APP_2')
library(causalTree)
library(dplyr)
library(ggplot2)
#install.packages("grf")
library(grf)
setwd("G:/causal_tree/validations/out")
################################################################################################
### initiate a dataset to store mse for different designs
cv_mse_df <- data.frame(matrix(ncol = 2, nrow = 0))
colnames(cv_mse_df) <- c('design', 'cv_mse')
################################################################################################
# generate all of the designs
##  RQ1: How accurate are the heterogeneous treatment effect estimation models under
##  different distributions of treatment effect moderating variable(s)?
### Design 1
set.seed(42)
d1 <- data.frame(matrix(ncol = 0, nrow = 8000))
d1$x1 <- runif(n = 8000, min = 0, max = 1)
d1$x2 <- rnorm(n = 8000, mean = 0, sd = 1)
d1$treatment <- unlist(append(list(rep(0,4000)), list(rep(1,4000))))
d1$error <- rnorm(n = 8000, mean = 0, sd = 0.01)
d1 <- d1 %>% mutate(y = (x1/2+x2) + (1/2)*(2*treatment -1)*(x1/2) + error,
true_effect = x1/2)
### Design 2
set.seed(42)
d2 <- data.frame(matrix(ncol = 0, nrow = 8000))
d2$x1 <- rnorm(n = 8000, mean = 0.5, sd = 0.25)
d2$x2 <- rnorm(n = 8000, mean = 0, sd = 1)
d2$treatment <- unlist(append(list(rep(0,4000)), list(rep(1,4000))))
d2$error <- rnorm(n = 8000, mean = 0, sd = 0.01)
d2 <- d2 %>% mutate(y = (x1/2+x2) + (1/2)*(2*treatment -1)*(x1/2) + error,
true_effect = x1/2)
### Design 3
set.seed(42)
d3 <- data.frame(matrix(ncol = 0, nrow = 8000))
d3$x1 <- rnorm(n = 8000, mean = 0.5, sd = 0.25)
d3$x2 <- rbeta(n = 8000, shape1 = 0.5, shape2 = 0.5)
d3$treatment <- unlist(append(list(rep(0,4000)), list(rep(1,4000))))
d3$error <- rnorm(n = 8000, mean = 0, sd = 0.01)
d3 <- d3 %>% mutate(y = (x1/2+x2) + (1/2)*(2*treatment -1)*(x1/2) + error,
true_effect = x1/2)
## RQ2: How accurate are the heterogeneous treatment effect estimation models for different
## functional form specifications?
set.seed(42)
d <- data.frame(matrix(ncol = 0, nrow = 8000))
d$x1 <- runif(n = 8000, min = -2, max = 2)
d$x2 <- rnorm(n = 8000, mean = 0, sd = 1.5)
d$treatment <- unlist(append(list(rep(0,4000)), list(rep(1,4000))))
d$error <- rnorm(n = 8000, mean = 0, sd = 0.01)
### Design 4
d4 <- d %>% mutate(y = (x1/2+x2) + (1/2)*(2*treatment -1)*(x1/2) + error,
true_effect = x1/2)
### Design 5
d5 <- d %>% mutate(y = (x1/2+x2) + (1/2)*(2*treatment -1)*(x1^2) + error,
true_effect = x1^2)
### Design 6
d6 <- d %>%  mutate(k_x = ifelse(x1 > 0, x1, 0)) %>%
mutate(y = (x1/2+x2) + (1/2)*(2*treatment -1)*(k_x) + error,
true_effect = k_x) %>%
select(-k_x)
### Design 7
d7 <- d %>%  mutate(k_x = floor(x1)) %>%
mutate(y = (x1/2+x2) + (1/2)*(2*treatment -1)*(k_x) + error,
true_effect = k_x) %>%
select(-k_x)
### Design 8
d8 <- d %>%  mutate(k_x = case_when(x1 < -1 ~ x1,
x1 >= -1 & x1 <= 1 ~ 0,
x1 > 1 ~ x1^3)) %>%
mutate(y = (x1/2+x2) + (1/2)*(2*treatment -1)*(k_x) + error,
true_effect = k_x) %>%
select(-k_x)
##	RQ3: How robust are the heterogeneous treatment effect estimation models
##  in the presence of large number of nuisance parameters?
### initiate base df
set.seed(42)
d <- data.frame(matrix(ncol = 0, nrow = 8000))
# add in values
d$x1 <- runif(n = 8000, min = -2, max = 2)
d$x2 <- rnorm(n = 8000, mean = 0, sd = 1.5)
#create a 8000 * 98 matrix from norm(0,1) to be nuisanse parameters
n <- 8000
p <- 98
d_matrix <- matrix(rnorm(n*p), n, p)
d <- cbind(d, d_matrix)
# set colnames for d
d_cols <- c()
for(i in 1:100){
d_cols <- append(d_cols, paste0("x",i))
}
colnames(d) <- d_cols
d$treatment <- unlist(append(list(rep(0,4000)), list(rep(1,4000))))
d$error <- rnorm(n = 8000, mean = 0, sd = 0.01)
### Design 9
d9 <- d %>% mutate(y = (x1/2+x2) + (1/2)*(2*treatment -1)*(x1/2) + error,
true_effect = x1/2) %>%
select(x1,x2,treatment, error, y, true_effect)
### Design 10
d10 <- d %>% mutate(y = (x1/2+x2+x3+x4+x5+x6+x7+x8+x9+x10) + (1/2)*(2*treatment -1)*(x1/2) + error,
true_effect = x1/2) %>%
select(x1,x2,x3,x4,x5,x6,x7,x8,x9,x10, treatment, error, y, true_effect)
### Design 11
d11 <- d %>% mutate(y = (x1/2+x2+x3+x4+x5+x6+x7+x8+x9+x10+x11+x12+x13+x14+x15+x16+x17+x18+x19+x20+
x21+x22+x23+x24+x25+x26+x27+x28+x29+x30+x31+x32+x33+x34+x35+x36+x37+x38+x39+x40+
x41+x42+x43+x44+x45+x46+x47+x48+x49+x50) + (1/2)*(2*treatment -1)*(x1/2) + error,
true_effect = x1/2) %>%
select(x1,x2,x3,x4,x5,x6,x7,x8,x9,x10,x11,x12,x13,x14,x15,x16,x17,x18,x19,x20,
x21,x22,x23,x24,x25,x26,x27,x28,x29,x30,x31,x32,x33,x34,x35,x36,x37,x38,x39,x40,
x41,x42,x43,x44,x45,x46,x47,x48,x49,x50, treatment, error, y, true_effect)
### Design 12
d12 <- d %>% mutate(y = (x1/2+x2+x3+x4+x5+x6+x7+x8+x9+x10+x11+x12+x13+x14+x15+x16+x17+x18+x19+x20+
x21+x22+x23+x24+x25+x26+x27+x28+x29+x30+x31+x32+x33+x34+x35+x36+x37+x38+x39+x40+
x41+x42+x43+x44+x45+x46+x47+x48+x49+x50+x51+x52+x53+x54+x55+x56+x57+x58+x59+x60+
x61+x62+x63+x64+x65+x66+x67+x68+x69+x70+x71+x72+x73+x74+x75+x76+x77+x78+x79+x80+
x81+x82+x83+x84+x85+x86+x87+x88+x89+x90+x91+x92+x93+x94+x95+x96+x97+x98+x99+x100) +
(1/2)*(2*treatment -1)*(x1/2) + error,
true_effect = x1/2)
### RQ4: How accurate are the models when the treatment effect varies along multiple moderator variables?
d_rq4 <- d %>% select(x1,x2,x3,x4,x5,x6,x7,x8,x9,x10, treatment, error)
### Design 13
d13 <- d_rq4 %>%  mutate(y = ((x1+x2+x3+x4+x5+x6)/2+x7+x8+x9+x10) + (1/2)*(2*treatment -1)*(x1+x2) + error,
true_effect = x1+x2)
### Design 14
d14 <- d_rq4 %>%  mutate(y = ((x1+x2+x3+x4+x5+x6)/2+x7+x8+x9+x10) + (1/2)*(2*treatment -1)*(x1+x2+x3+x4) + error,
true_effect = x1+x2+x3+x4)
### Design 15
d15 <- d_rq4 %>%  mutate(y = ((x1+x2+x3+x4+x5+x6)/2+x7+x8+x9+x10) + (1/2)*(2*treatment -1)*(x1+x2+x3+x4+x5+x6) + error,
true_effect = x1+x2+x3+x4+x5+x6)
### RQ5: How robust are the models when a number of moderator variables are unobserved?
design_lst <- list(d1,d2,d3,d4,d5,d6,d7,d8,d9,d10,d11,d12,d13,d14,d15)
################################################################################################
cv_mse_df <- data.frame(matrix(ncol = 2, nrow = 0))
count <- 1
for(df in design_lst){
df_cv <- data.frame(matrix(ncol = 0, nrow = 0))
# 10 fold cross validation
# shuffle the dataset
n <- nrow(df)
#Create 10 equally size folds
set.seed(123)
df <- df[sample(n), ]
folds <- cut(seq(1,n), breaks = 10, labels = FALSE)
#get the number of columns
n_col <- ncol(df) - 4
#Perform 10 fold cross validation
for(i in 1:10){
#Segement data by fold using the which() function
testIndexes <- which(folds==i,arr.ind=TRUE)
test_set <- df[testIndexes, ]
train_set <- df[-testIndexes, ]
#prepare data for forest training
X_train <- as.matrix(train_set %>% select(1:n_col))
Y <- as.matrix(train_set %>% select(y))
W <- as.matrix(train_set %>% select(treatment))
X_test <- as.matrix(test_set %>% select(1:n_col))
# train random forest
rf <- causal_forest(X_train, Y, W)
#make prediction on test set
test_set$pred_effect <- predict(rf, X_test)$prediction
df_cv <- rbind(df_cv, test_set)
}
mse_cv <- c()
#calculate cv mse
for (j in 1:10){
testIndexes <- which(folds==j,arr.ind=TRUE)
test_cv <- df_cv[testIndexes, ]
mse <- mean((test_cv$pred_effect - test_cv$true_effect)^2)
mse_cv <- append(mse_cv, mse)
}
mean_mse <- mean(mse_cv)
df_mse_vec <- c(deparse(substitute(df)), mean_mse)
cv_mse_df[nrow(cv_mse_df) + 1, ] <- df_mse_vec
#plotting
p <-  ggplot(df_cv, aes(x=x1, y=pred_effect)) +
geom_point(shape=1) +
geom_smooth(color = 'blue') +
geom_smooth(data = test_set, aes(x = x1, y = true_effect), color = 'red') +
scale_colour_manual(values=c("blue", "red"))
ggsave (paste0(count, ".png"), device = "png")
-
count <- count + 1
}
write.csv(cv_mse_df, file = 'mse_data_frame.csv', row.names = FALSE)
library(causalTree)
library(dplyr)
library(ggplot2)
#install.packages("grf")
library(grf)
setwd("G:/causal_tree/validations/out")
################################################################################################
### initiate a dataset to store mse for different designs
cv_mse_df <- data.frame(matrix(ncol = 2, nrow = 0))
colnames(cv_mse_df) <- c('design', 'cv_mse')
################################################################################################
# generate all of the designs
##  RQ1: How accurate are the heterogeneous treatment effect estimation models under
##  different distributions of treatment effect moderating variable(s)?
### Design 1
set.seed(42)
d1 <- data.frame(matrix(ncol = 0, nrow = 8000))
d1$x1 <- runif(n = 8000, min = 0, max = 1)
d1$x2 <- rnorm(n = 8000, mean = 0, sd = 1)
d1$treatment <- unlist(append(list(rep(0,4000)), list(rep(1,4000))))
d1$error <- rnorm(n = 8000, mean = 0, sd = 0.01)
d1 <- d1 %>% mutate(y = (x1/2+x2) + (1/2)*(2*treatment -1)*(x1/2) + error,
true_effect = x1/2)
### Design 2
set.seed(42)
d2 <- data.frame(matrix(ncol = 0, nrow = 8000))
d2$x1 <- rnorm(n = 8000, mean = 0.5, sd = 0.25)
d2$x2 <- rnorm(n = 8000, mean = 0, sd = 1)
d2$treatment <- unlist(append(list(rep(0,4000)), list(rep(1,4000))))
d2$error <- rnorm(n = 8000, mean = 0, sd = 0.01)
d2 <- d2 %>% mutate(y = (x1/2+x2) + (1/2)*(2*treatment -1)*(x1/2) + error,
true_effect = x1/2)
### Design 3
set.seed(42)
d3 <- data.frame(matrix(ncol = 0, nrow = 8000))
d3$x1 <- rnorm(n = 8000, mean = 0.5, sd = 0.25)
d3$x2 <- rbeta(n = 8000, shape1 = 0.5, shape2 = 0.5)
d3$treatment <- unlist(append(list(rep(0,4000)), list(rep(1,4000))))
d3$error <- rnorm(n = 8000, mean = 0, sd = 0.01)
d3 <- d3 %>% mutate(y = (x1/2+x2) + (1/2)*(2*treatment -1)*(x1/2) + error,
true_effect = x1/2)
## RQ2: How accurate are the heterogeneous treatment effect estimation models for different
## functional form specifications?
set.seed(42)
d <- data.frame(matrix(ncol = 0, nrow = 8000))
d$x1 <- runif(n = 8000, min = -2, max = 2)
d$x2 <- rnorm(n = 8000, mean = 0, sd = 1.5)
d$treatment <- unlist(append(list(rep(0,4000)), list(rep(1,4000))))
d$error <- rnorm(n = 8000, mean = 0, sd = 0.01)
### Design 4
d4 <- d %>% mutate(y = (x1/2+x2) + (1/2)*(2*treatment -1)*(x1/2) + error,
true_effect = x1/2)
### Design 5
d5 <- d %>% mutate(y = (x1/2+x2) + (1/2)*(2*treatment -1)*(x1^2) + error,
true_effect = x1^2)
### Design 6
d6 <- d %>%  mutate(k_x = ifelse(x1 > 0, x1, 0)) %>%
mutate(y = (x1/2+x2) + (1/2)*(2*treatment -1)*(k_x) + error,
true_effect = k_x) %>%
select(-k_x)
### Design 7
d7 <- d %>%  mutate(k_x = floor(x1)) %>%
mutate(y = (x1/2+x2) + (1/2)*(2*treatment -1)*(k_x) + error,
true_effect = k_x) %>%
select(-k_x)
### Design 8
d8 <- d %>%  mutate(k_x = case_when(x1 < -1 ~ x1,
x1 >= -1 & x1 <= 1 ~ 0,
x1 > 1 ~ x1^3)) %>%
mutate(y = (x1/2+x2) + (1/2)*(2*treatment -1)*(k_x) + error,
true_effect = k_x) %>%
select(-k_x)
##	RQ3: How robust are the heterogeneous treatment effect estimation models
##  in the presence of large number of nuisance parameters?
### initiate base df
set.seed(42)
d <- data.frame(matrix(ncol = 0, nrow = 8000))
# add in values
d$x1 <- runif(n = 8000, min = -2, max = 2)
d$x2 <- rnorm(n = 8000, mean = 0, sd = 1.5)
#create a 8000 * 98 matrix from norm(0,1) to be nuisanse parameters
n <- 8000
p <- 98
d_matrix <- matrix(rnorm(n*p), n, p)
d <- cbind(d, d_matrix)
# set colnames for d
d_cols <- c()
for(i in 1:100){
d_cols <- append(d_cols, paste0("x",i))
}
colnames(d) <- d_cols
d$treatment <- unlist(append(list(rep(0,4000)), list(rep(1,4000))))
d$error <- rnorm(n = 8000, mean = 0, sd = 0.01)
### Design 9
d9 <- d %>% mutate(y = (x1/2+x2) + (1/2)*(2*treatment -1)*(x1/2) + error,
true_effect = x1/2) %>%
select(x1,x2,treatment, error, y, true_effect)
### Design 10
d10 <- d %>% mutate(y = (x1/2+x2+x3+x4+x5+x6+x7+x8+x9+x10) + (1/2)*(2*treatment -1)*(x1/2) + error,
true_effect = x1/2) %>%
select(x1,x2,x3,x4,x5,x6,x7,x8,x9,x10, treatment, error, y, true_effect)
### Design 11
d11 <- d %>% mutate(y = (x1/2+x2+x3+x4+x5+x6+x7+x8+x9+x10+x11+x12+x13+x14+x15+x16+x17+x18+x19+x20+
x21+x22+x23+x24+x25+x26+x27+x28+x29+x30+x31+x32+x33+x34+x35+x36+x37+x38+x39+x40+
x41+x42+x43+x44+x45+x46+x47+x48+x49+x50) + (1/2)*(2*treatment -1)*(x1/2) + error,
true_effect = x1/2) %>%
select(x1,x2,x3,x4,x5,x6,x7,x8,x9,x10,x11,x12,x13,x14,x15,x16,x17,x18,x19,x20,
x21,x22,x23,x24,x25,x26,x27,x28,x29,x30,x31,x32,x33,x34,x35,x36,x37,x38,x39,x40,
x41,x42,x43,x44,x45,x46,x47,x48,x49,x50, treatment, error, y, true_effect)
### Design 12
d12 <- d %>% mutate(y = (x1/2+x2+x3+x4+x5+x6+x7+x8+x9+x10+x11+x12+x13+x14+x15+x16+x17+x18+x19+x20+
x21+x22+x23+x24+x25+x26+x27+x28+x29+x30+x31+x32+x33+x34+x35+x36+x37+x38+x39+x40+
x41+x42+x43+x44+x45+x46+x47+x48+x49+x50+x51+x52+x53+x54+x55+x56+x57+x58+x59+x60+
x61+x62+x63+x64+x65+x66+x67+x68+x69+x70+x71+x72+x73+x74+x75+x76+x77+x78+x79+x80+
x81+x82+x83+x84+x85+x86+x87+x88+x89+x90+x91+x92+x93+x94+x95+x96+x97+x98+x99+x100) +
(1/2)*(2*treatment -1)*(x1/2) + error,
true_effect = x1/2)
### RQ4: How accurate are the models when the treatment effect varies along multiple moderator variables?
d_rq4 <- d %>% select(x1,x2,x3,x4,x5,x6,x7,x8,x9,x10, treatment, error)
### Design 13
d13 <- d_rq4 %>%  mutate(y = ((x1+x2+x3+x4+x5+x6)/2+x7+x8+x9+x10) + (1/2)*(2*treatment -1)*(x1+x2) + error,
true_effect = x1+x2)
### Design 14
d14 <- d_rq4 %>%  mutate(y = ((x1+x2+x3+x4+x5+x6)/2+x7+x8+x9+x10) + (1/2)*(2*treatment -1)*(x1+x2+x3+x4) + error,
true_effect = x1+x2+x3+x4)
### Design 15
d15 <- d_rq4 %>%  mutate(y = ((x1+x2+x3+x4+x5+x6)/2+x7+x8+x9+x10) + (1/2)*(2*treatment -1)*(x1+x2+x3+x4+x5+x6) + error,
true_effect = x1+x2+x3+x4+x5+x6)
### RQ5: How robust are the models when a number of moderator variables are unobserved?
design_lst <- list(d1,d2,d3,d4,d5,d6,d7,d8,d9,d10,d11,d12,d13,d14,d15)
################################################################################################
cv_mse_df <- data.frame(matrix(ncol = 2, nrow = 0))
count <- 1
for(df in design_lst){
df_cv <- data.frame(matrix(ncol = 0, nrow = 0))
# 10 fold cross validation
# shuffle the dataset
n <- nrow(df)
#Create 10 equally size folds
set.seed(123)
df <- df[sample(n), ]
folds <- cut(seq(1,n), breaks = 10, labels = FALSE)
#get the number of columns
n_col <- ncol(df) - 4
#Perform 10 fold cross validation
for(i in 1:10){
#Segement data by fold using the which() function
testIndexes <- which(folds==i,arr.ind=TRUE)
test_set <- df[testIndexes, ]
train_set <- df[-testIndexes, ]
#prepare data for forest training
X_train <- as.matrix(train_set %>% select(1:n_col))
Y <- as.matrix(train_set %>% select(y))
W <- as.matrix(train_set %>% select(treatment))
X_test <- as.matrix(test_set %>% select(1:n_col))
# train random forest
rf <- causal_forest(X_train, Y, W)
#make prediction on test set
test_set$pred_effect <- predict(rf, X_test)$prediction
df_cv <- rbind(df_cv, test_set)
}
mse_cv <- c()
#calculate cv mse
for (j in 1:10){
testIndexes <- which(folds==j,arr.ind=TRUE)
test_cv <- df_cv[testIndexes, ]
mse <- mean((test_cv$pred_effect - test_cv$true_effect)^2)
mse_cv <- append(mse_cv, mse)
}
mean_mse <- mean(mse_cv)
df_mse_vec <- c(deparse(substitute(df)), mean_mse)
cv_mse_df[nrow(cv_mse_df) + 1, ] <- df_mse_vec
#plotting
p <-  ggplot(df_cv, aes(x=x1, y=pred_effect)) +
geom_point(shape=1) +
geom_smooth(color = 'blue') +
geom_smooth(data = test_set, aes(x = x1, y = true_effect), color = 'red') +
scale_colour_manual(values=c("blue", "red"))
ggsave (paste0(count, ".png"), device = "png")
count <- count + 1
}
write.csv(cv_mse_df, file = 'mse_data_frame.csv', row.names = FALSE)
View(cv_mse_df)
cv_mse_df <- cv_mse_df %>% select(X2) %>% rename(mse = X2)
cv_mse_df <- cv_mse_df %>% rename(design = X1, mse = X2)
write.csv(cv_mse_df, file = 'mse_data_frame.csv', row.names = FALSE)
cv_mse_df$desing <- c(1:15)
cv_mse_df$design <- c(1:15)
cv_mse_df <- cv_mse_df %>% select(-desing)
cv_mse_df <- cv_mse_df %>% select(design, mse)
write.csv(cv_mse_df, file = 'mse_data_frame.csv', row.names = FALSE)
install.packages("FSInteract")
#install.packages("FSInteract")
library(FSInteract)
z <- matrix(rbinom(250*500, 1, 0.3), 250, 500)
z0 <- matrix(rbinom(250*500, 1, 0.3), 250, 500)
z
## Generate two binary matrices
z <- matrix(rbinom(250*500, 1, 0.3), 250, 500)
z0 <- matrix(rbinom(250*500, 1, 0.3), 250, 500)
## Make the first and second cols of z identical
## so the set 1, 2 has prevalence roughly 0.3 compared
## to roughly 0.09 for any other pair of columns
z[, 1] <- z[, 2]
## Similarly for z0
z0[, 3] <- z0[, 4]
## Market basket analysis
out1 <- RIT(z)
out1[1:5, ]
## Finding interactions
out2 <- RIT(z, z0)
out2$Class1[1:5, ]
out2$Class0[1:5, ]
## Can also perform the above using sparse matrices
S <- Matrix(z, sparse=TRUE)
out1
## Finding interactions
out2 <- RIT(z, z0)
out2$Class1[1:5, ]
out2$Class0[1:5, ]
